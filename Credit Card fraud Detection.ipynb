{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47746ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # For data manipulation\n",
    "from sklearn.model_selection import train_test_split  # To split the dataset into training and testing sets\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic Regression model\n",
    "from sklearn.metrics import classification_report, confusion_matrix  # For model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e604fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time   V1   V2   V3  Amount  Class\n",
      "0     0  1.0  1.0  0.1     100      0\n",
      "1     1  2.0  1.5  0.4     200      0\n",
      "2     2  1.5  1.2  0.3     150      0\n",
      "3     3  1.2  1.8  0.5     300      1\n",
      "4     4  2.2  1.1  0.2     250      0\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('credit_card_fraud.csv')  # Replace with your CSV file path\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f16d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop('Class', axis=1)  # Features\n",
    "y = data['Class']  # Target variable (0 = not fraud, 1 = fraud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef8c8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (8, 5), Testing set shape: (2, 5)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the sets\n",
    "print(f\"Training set shape: {X_train.shape}, Testing set shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2479c50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ee00c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b59abd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1 1]\n",
      " [0 0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.50      0.25      0.33         2\n",
      "weighted avg       1.00      0.50      0.67         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))  # Confusion matrix\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))  # Handle zero division\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3c41dde",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-9-88204a428708>, line 81)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-88204a428708>\"\u001b[1;36m, line \u001b[1;32m81\u001b[0m\n\u001b[1;33m    \"\"\"\"\u001b[0m\n\u001b[1;37m        \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The output of the confusion matrix and classification report you've provided offers insight into the performance of your logistic regression model for credit card fraud detection. Hereâ€™s an explanation of what each part means:\n",
    "\n",
    "### Confusion Matrix\n",
    "```\n",
    "Confusion Matrix:\n",
    "[[1 1]\n",
    " [0 0]]\n",
    "```\n",
    "- **Matrix Structure**: The confusion matrix is structured as follows:\n",
    "\n",
    "    \\[\n",
    "    \\begin{array}{c|cc}\n",
    "        & \\text{Predicted 0} & \\text{Predicted 1} \\\\\n",
    "        \\hline\n",
    "        \\text{Actual 0} & 1 & 1 \\\\\n",
    "        \\text{Actual 1} & 0 & 0 \\\\\n",
    "    \\end{array}\n",
    "    \\]\n",
    "\n",
    "- **Interpretation**:\n",
    "  - **True Negatives (TN)**: 1 (one non-fraudulent transaction correctly identified as non-fraudulent).\n",
    "  - **False Positives (FP)**: 1 (one non-fraudulent transaction incorrectly identified as fraudulent).\n",
    "  - **False Negatives (FN)**: 0 (no fraudulent transactions were incorrectly identified as non-fraudulent).\n",
    "  - **True Positives (TP)**: 0 (no fraudulent transactions were correctly identified as fraudulent).\n",
    "\n",
    "### Classification Report\n",
    "```\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.50      0.67         2\n",
    "           1       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.50         2\n",
    "   macro avg       0.50      0.25      0.33         2\n",
    "weighted avg       1.00      0.50      0.67         \n",
    "```\n",
    "\n",
    "#### Breakdown of the Metrics:\n",
    "- **Precision**: \n",
    "  - For class 0 (not fraud): 1.00 (indicating that all predictions of non-fraud are correct).\n",
    "  - For class 1 (fraud): 0.00 (indicating that no predictions of fraud are correct).\n",
    "  \n",
    "- **Recall**:\n",
    "  - For class 0: 0.50 (indicating that 50% of actual non-fraud cases were correctly identified).\n",
    "  - For class 1: 0.00 (indicating that no actual fraud cases were identified).\n",
    "\n",
    "- **F1-Score**:\n",
    "  - For class 0: 0.67 (a balance between precision and recall).\n",
    "  - For class 1: 0.00 (no balance as there are no true positives).\n",
    "\n",
    "- **Support**:\n",
    "  - For class 0: 2 (total instances of non-fraud).\n",
    "  - For class 1: 0 (no instances of fraud in the test set).\n",
    "\n",
    "- **Overall Accuracy**: \n",
    "  - 0.50 (50% of the total instances were correctly classified).\n",
    "\n",
    "- **Macro Average**: \n",
    "  - Averages the precision, recall, and F1-score for both classes without considering the class imbalance. It gives equal weight to both classes.\n",
    "\n",
    "- **Weighted Average**:\n",
    "  - Takes the support (number of actual occurrences) into account, giving more weight to classes with more instances.\n",
    "\n",
    "### Key Takeaways\n",
    "1. **Model Performance**:\n",
    "   - The model is struggling to identify fraudulent transactions (class 1) as indicated by the recall and precision of 0.00.\n",
    "   - The confusion matrix shows that it incorrectly classified one non-fraudulent transaction as fraudulent.\n",
    "\n",
    "2. **Class Imbalance**:\n",
    "   - The dataset may be imbalanced, with significantly more non-fraudulent transactions than fraudulent ones, leading to poor performance in detecting fraud.\n",
    "\n",
    "3. **Next Steps**:\n",
    "   - Consider techniques to handle class imbalance, such as:\n",
    "     - **Resampling**: Oversampling the minority class (fraud) or undersampling the majority class (non-fraud).\n",
    "     - **Using different algorithms**: Consider algorithms better suited for imbalanced datasets, such as Decision Trees, Random Forests, or Gradient Boosting.\n",
    "     - **Anomaly Detection Techniques**: Since fraud cases are rare, consider treating this as an anomaly detection problem instead.\n",
    "\n",
    "This analysis shows that while the model can identify non-fraudulent transactions accurately, it fails to detect any fraudulent ones\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac83e5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
